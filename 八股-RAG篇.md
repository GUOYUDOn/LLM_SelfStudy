### 1. Agent

![image-20250321150505323](C:\Users\ROG\AppData\Roaming\Typora\typora-user-images\image-20250321150505323.png)

在以 LLM 驱动的自主代理系统中，LLM 充当 Agent 的大脑，并有以下几个组件：

- **规划（Planning）**

Agent 将大型任务分解为较小的、可管理的子目标，从而能够高效处理复杂任务。可以对过去的行为进行自我批评和自我反省，从错误中吸取教训并为未来的步骤进行改进，从而提高最终结果的质量。

- **记忆（Memory）**

上下文学习都是利用模型的短期记忆来学习的。而长期记忆则为代理提供了在较长时间内保留和调用信息的能力，通常是通过利用外部向量存储和快速检索实现的。

- **工具（Tools）**

Agent 学习调用外部的 API 来获取额外信息，包括即时信息、代码执行能力、对专有信息源的访问等。

#### 1.1 规划（Planning）

##### 1.1.1 任务分解

- **思维链（CoT，Chain of thought）**：指示模型“逐步思考”，将困难的任务分解为更小、更简单的步骤。CoT 将大任务转化为多个可管理的任务，并阐明对模型思维过程的解释。
- **思维树（ToT，Tree of Thoughts）**：通过在每一步探索多种推理可能性来扩展 CoT。它首先将问题分解为多个思考步骤，每个步骤生成多个思考，从而创建一个树状结构。搜索过程可以是 BFS（广度优先搜索）或 DFS（深度优先搜索），通过判断与评估，最终选择最优路径。

##### 1.1.2 自我反省

- **ReAct**：它是一种结合推理和行动的范式，目的是让 LLM 在与环境交互时，既能“思考”，也能“行动”。交替进行重复多次：推理思考（Thought）→ 做出动作（Action）→ 观察结果（Observation）。在知识密集型任务表现良好。
- **Reflexion**：它是一个框架，用于为代理提供动态记忆和自我反思能力，以提高推理技能。核心流程为：执行尝试（Try）→ 失败检测（Detect Failure）→  自我反思（Reflect）→  策略修正（Improve）→  重新尝试（Retry），直到任务成功或达到最大轮次。
- **Chain of Hindsight（CoH，事后链）**：利用历史轨迹中的“成功经验”来生成训练样本，从已有的高质量对话或任务执行记录中，回过头（hindsight）提取出有效的中间步骤和思路路径，把它们变成新的一组监督训练数据，以此训练模型具有更强的推理与行为能力。

#### 1.2 **记忆（Memory）**

- **感官记忆**：作为原始输入（包括文本、图像或其他模态）的学习嵌入表示。
- **短期记忆**：作为上下文学习。它简短而有限，因为它受 Transformer 的有限上下文窗口长度的限制。
- **长期记忆**：作为代理在查询时可以处理的外部向量存储，可通过快速检索访问。

#### 1.3 工具（Tools）

- **MRKL**： LLM 用作路由器，将查询路由到最合适的专家模块。
-  **Toolformer** ：微调 LM 以学习使用外部工具 API。
- **HuggingGPT**：以 ChatGPT 作为任务规划器，根据模型描述选择 HuggingFace 平台中可用的模型，并根据执行结果总结响应。有四个阶段：任务规划 → 模型选择 → 任务执行 → 响应生成。
- **API-Bank**：LLM 专用的、用于多工具调用（multi-tool usage）任务评估和训练的数据集与基准平台。包含53 个真实 Web API 工具，多角度测评。

#### 1.4 存在的挑战

- **有限上下文长度**：受限上下文容量限制了历史信息、详细说明、API 调用和响应。
- **长期规划和任务分解中的挑战**：LLM 在面临意外错误时难以调整计划。
- **自然语言接口的可靠性**：模型输出的可靠性值得怀疑，因为 LLM 可能会犯格式错误，偶尔会表现出叛逆行为（例如拒绝遵循指令）。



### 2. 提示词工程（Prompt Engineering）

设计有效的提示词以指导模型执行期望任务的方法被称为提示工程，其应用于开发和优化提示词（Prompt），帮助用户有效地将语言模型用于各种应用场景和研究领域。可利用提示工程来提高大语言模型处理复杂任务场景的能力，如问答和算术推理能力。

**提示词要素**如下：

- **指令**：想要模型执行的特定任务。
- **上下文**：包含外部信息或额外的上下文信息，引导语言模型更好地响应。
- **输入数据**：用户输入的内容或问题。
- **输出指示**：指定输出的类型或格式。

**提示词要点**如下：

- **具体性**：非常具体地说明你希望模型执行的指令和任务。
- **避免不明确**：非常具体、简洁并且切中要点的。
- **做什么**：避免说不要做什么，而应该说要做什么。

**提示词技术**如下：

- 零样本提示
- 少样本提示
- 链式思考提示（CoT）
- 生成知识提示
- 链式提示（prompt chaining）
- 思维树（ToT）：引导 LLM 在一次提示中对中间思维做出评估。
- 检索增强生成（RAG）
- ReAct：明确结构（`Thought → Action → Observation`）来引导语言模型进行推理+调用工具。



### 3. RAG

#### 3.1 信息检索

- **基于统计信息的关键字匹配**：`sparse embedding`，embedding 向量的大部分字段都是 0。典型算法：`TF-IDF`、`BM25`。通过分析语料库的词频和分布，作为评估文档相关性的基础。方法简单，适用范围广，但是无法理解语义。适合**关键词匹配**任务。
- **基于深度学习模型的上下文和语义理解**：`dense embedding`，embedding 向量的大部分字段都非零。典型算法：`Word2Vec`、`BERT`。`Word2Vec`首次尝试使用高维向量来表示单词，能分辨它们细微的语义差别。`BERT`是基于 transformer 的预训练语言模型，self-attention 能量化给定单词与句子中其他单词的关联性程度，得到 `dense vector` 的输出。BERT 严重依赖预训练数据集的领域知识，可以微调缓解。典型模型：`bge-v1.5`。适合**语义搜索**任务。
- **“学习型”表示**：`learned sparse embedding`，既有下文和语义理解能力，又有稀疏表示的可解释性。先通过 BERT 等深度学习模型生成 dense embedding，再引入额外的步骤对以上 dense embedding 进行稀疏化，得到一个 sparse embedding。典型算法：`bge-m3`。它引入了 Token Importance Estimation，能够辨别相邻或相关的 token 的重要性，即使这些 token 在文本中没有明确出现。同时具备精确匹配和语义理解两大能力，在领域外场景有很强的泛化能力。

#### 3.2 Embedding & retrieval 工作原理

1）**BERT** dense embedding 工作流：

- **`Tokenization`**：将输入文本转成 token 序列，BERT 还会插入两个特殊的 token：`[CLS]` token 表示开始，`[SEP]` token 表示一个句子的结束。
- **`Embedding`**：使用 embedding matrix 将每个 token 转换为一个向量。
- **`Encoding`**：这些向量通过多层 encoder，每层由 self-attention 和 FFN 组成，会根据所有其他 token 提供的上下文细化每个 token 的表示。
- **`Output`**：输出一系列最终的 embedding vectors。

2）**BGE-M3**（BERT-based learned sparse embedding），多功能，多语言，多粒度：

- **`Token importance estimation`**：BERT 在分类/相似性比较时仅关注第一个 token（`[CLS]`）， BGE-M3 则扩大到关注序列中的每个 token `Hi`。
- 线性变换：在 encoder 的输出层上又增加一个线性层，计算每个 token 的 importance weights `W_lex`。
- 激活函数：`W_lex` 和 `Hi` 的乘积经过 ReLU 激活函数，得到每个 token 的术语权重 `Wt`（每个 token 对应词汇表的分数）
- 稀释激活：对上述分布应用稀疏操作（Top_K，门控），只保留 top_K 重要的 token 的激活值，其余为0。
- （可选）精调（fine-tune）：用数据训练，让正样本和负样本的分数差变大。

#### 3.3 `rerank` 增强

对 embedding model 检索得到的多个结果（对应多个分数）， 重新计算它们的相似性分数，给出一个排名。

<img src="C:\Users\ROG\AppData\Roaming\Typora\typora-user-images\image-20250322182817002.png" alt="image-20250322182817002" style="zoom:67%;" />

- BGE-M3 属于 `bi-encoder embedding model`，两个句子分别输入模型，得到各自的 embedding， 然后根据 embedding vector 计算相似度。速度快，准确性相对低。
- bge-reranker-v2-m3 属于 `cross-encoder model`，同时对两个句子编码，输出一个相似度分数。使用CrossEncoder，拼接两个句子，接入 Transformer Encoder，一般用 `[CLS]` 的输出向量接一个全连接层，输出一个匹配分数。速度慢，准确性高。



### 4. RAG 中的分块方式有哪些？

将大块文本分割成小段落，确保用户查询与内容之间的相似度得分更高，从而提高搜索结果的相关性和准确性。分块要考虑：1）文档的类型，长文档还是段文档；2）考虑用户查询的长度和复杂性；3）检索结果的使用。

- 固定大小分块
- 递归分割：使用分隔符以分层和迭代的方式将输入文本分解成更小的块。初始分割：使用主要分隔符（章节段落）分割，递归调用：初始分割未能满足，则使用次级分隔符（句子）分割，直到所有块均达到所需大小。
- 上下文感知分块（Context-aware Chunking）：基于形式结构的分块方法。`TokenSplitter` 使用token划分文档，`SentenceSplitter` 通过句子边界分割文本。
- 语义分块：确保每个生成的块都在语义上完整并能够独立表达清晰的信息。首先分析文本识别语义单元（主题，逻辑段落），之后基于语义单元分割文本。
- Late Chunking：先对整段文本编码成 embedding，然后再对 embedding 结果进行切分。先将文本传入模型，生成每个 token 的向量表示，再将文本分块（可能存在重叠），对于每个分块，使用池化将所有 token 的向量表示聚合成一个分块嵌入。
- 基于大模型的分块：jina对0.5b模型训练，可以对多种文档进行分块。



### 5. RAG 的基础流程是什么？

- **Query 编码**：将用户输入的问题编码成向量。
- **检索文档**：在向量数据库中检索与 query 最相关的文本块。
- **对检索出来的文档进行排序**：在粗召之后进行精排，返回 Top_K 文档。
- **构造 Prompt**：将检索到的内容与原始问题拼接成 Prompt，作为 LLM 的输入。
- **生成答案**：由 LLM 基于上下文生成最终回答。



### 6. RAG 的核心技术是什么？

- **Embedding 模型**：将文本转化为语义向量，如 BGE，支持多语言与多粒度表达。
- **分块策略（Chunking）**：将知识库中的长文档切分为适合检索的片段。
- **向量检索**：从大规模文本中召回相关内容。
- **Prompt 构造策略**：将检索到的上下文与用户问题组合成 prompt。
- **Reranker**：使用 CrossEncoder 对候选文本重新打分，提高检索质量，提升生成答案的相关性。



### 7. 什么样的分块算是好的分块？

- **语义完整性**：每个块应尽量覆盖一个完整的语义单元，避免句子或段落被截断。
- **语义集中性**：每个块围绕单一主题展开，减少混杂信息，有利于 LLM 理解。
- **长度可控性**：控制每个块的 token 数在模型上下文窗口允许范围内。
- 提升检索命中率、减少生成过程中的幻觉（hallucination），并显著增强回答的准确性和一致性。



### 8. 有哪些信息检索（IR）系统效果评估指标？

- **召回率 （Recall）**：检索到的相关文档 / 全部相关文档的数量。可以评价系统找回相关文档的覆盖能力。

- **精确率 （Precision）**：检索到的相关文档 / 检索到的所有文档数量。用于衡量系统返回结果的准确性。

- **命中率（Hit@K）**：是否在 Top-K 检索结果中命中了至少一个相关项（命中 = 1）。

- **F1 分数**：
  $$
  F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
  $$
  在精确率和召回率之间做平衡的综合指标。

- **MRR（Mean Reciprocal Rank）**：平均倒数排名，第一个相关文档的倒数排名的平均值。
  $$
  MRR = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \frac{1}{rank_i}
  $$
  衡量系统能否把正确答案排在前面，越靠前越好。

- **MAP（Mean Average Precision）**：对每个查询计算平均精度（AP，对相关文档所在位置的 Precision求平均，受排序顺序影响），然后取所有查询的平均值。



### 9. RAG 与参数高效微调（PEFT）有何不同？

RAG（检索增强生成） 是通过引入外部知识库增强模型能力，而参数高效微调（PEFT）是通过微调少量参数来适配新任务或领域。

- **RAG**：不改动模型参数，引入外部知识辅助生成，推理时需要知识库。知识更新灵活、记忆外置，然而检索质量决定下限，工程复杂度高。
- **PEFT**：不改动大模型主体，只训练 LLM 少量附加参数。代表方法有：LoRA、Prefix Tuning、Adapter。推理时无需知识库。参数少、成本低、无须大规模训练，不过知识固定、需要训练样本。



### 10. 为什么做了 RAG 之后还要 SFT？

RAG 具有能力边界，它可以通过检索把信息喂给模型，但它无法确保模型准确使用这些信息，比如：知识引用错位，不根据上下文回答，回答格式不符合要求，逻辑不严谨等。SFT 可以强化模型对上下文的引用习惯，约束模型的回答格式、风格、推理流程，加强回答可信度。

RAG 和 SFT 是两种不同但互补的增强策略。RAG 通过引入外部知识提升回答能力，不改变模型参数；而 SFT 则通过训练让模型更精准地使用上下文、生成规范答案。在实际应用中，通常先构建 RAG 系统，再使用带 context 的 SFT 数据微调模型，从而获得“知识覆盖 + 表达精确”的双重优化效果。



### 11. RAG如何应对偏见和错误信息？

- 对数据源进行管理，选择权威、经过验证的数据源确保正确性；使用自动化工具（如Fairness Indicators）或人工审核，识别并剔除包含性别、种族、文化等偏见的内容；同时定期更新知识库，避免过时或已被证伪的内容被检索到。
- 对检索模块进行优化，设计检索算法时，除了文本匹配度，可加入可信度权重，优先返回高可信片段；引入多样性检索，避免单一检索产生错误与偏见；添加反事实检索，主动检索与输入问题矛盾的证据，供生成模型交叉验证。
- 对生成模块进行优化，进行提示工程，引导模型按照证据回复，基于客观事实生成答案。
- 后处理，基于模型检测生成结果中是否存在偏见或事实性错误；允许用户标记错误回答，将反馈数据用于模型迭代（强化学习、DPO）。





